{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOM7cSlApLWo7rWxeVPqF78",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "700f6b03ec444318b224bdb68546c088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_302a2753dd404a09aa457f713e4d13fe",
              "IPY_MODEL_2f6ce663aea14366a9a9813742e3cc5a",
              "IPY_MODEL_08b72327eff44a4eaecb22890aee69f7"
            ],
            "layout": "IPY_MODEL_13f84282ee3c413ca0ee439caa418751"
          }
        },
        "302a2753dd404a09aa457f713e4d13fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd46c591fb0147d59a4ffdf0bb593254",
            "placeholder": "​",
            "style": "IPY_MODEL_dbc5889c21684f7583a797e6d2819ec1",
            "value": "Epoch 1 of 3:   0%"
          }
        },
        "2f6ce663aea14366a9a9813742e3cc5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a08f1022bd4a298903ffaf015bfe6a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c50d960352e41e8823d9d2d5605c570",
            "value": 0
          }
        },
        "08b72327eff44a4eaecb22890aee69f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd2dc19e10f411fa6f593e09524cd0f",
            "placeholder": "​",
            "style": "IPY_MODEL_6149b294eca940448285629e48f2f91b",
            "value": " 0/3 [00:00&lt;?, ?it/s]"
          }
        },
        "13f84282ee3c413ca0ee439caa418751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd46c591fb0147d59a4ffdf0bb593254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc5889c21684f7583a797e6d2819ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2a08f1022bd4a298903ffaf015bfe6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c50d960352e41e8823d9d2d5605c570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffd2dc19e10f411fa6f593e09524cd0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6149b294eca940448285629e48f2f91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02d770f720884b7d9e23eac700919619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_883dd2ecee9946a7b1b06f422a1727cf",
              "IPY_MODEL_a66afffe1faa41e5973daf8491d1a413",
              "IPY_MODEL_ccea76e03c7d4ed69d7947d9e4560c28"
            ],
            "layout": "IPY_MODEL_eed2a5881d5b4d7f889b206777a26cbd"
          }
        },
        "883dd2ecee9946a7b1b06f422a1727cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ced074a8ed73436abf6a7792b29c832a",
            "placeholder": "​",
            "style": "IPY_MODEL_5f7ec9c5c29143ab844f40ad3ba3f5cf",
            "value": "Running Epoch 1 of 3:   0%"
          }
        },
        "a66afffe1faa41e5973daf8491d1a413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_793f744d6d474792b9a96fc8d713d6c1",
            "max": 1295,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_782f15e7a03c40ae8bb439421861cba0",
            "value": 0
          }
        },
        "ccea76e03c7d4ed69d7947d9e4560c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a163dc44c805403ab13accfe7a840ba8",
            "placeholder": "​",
            "style": "IPY_MODEL_edcc758b05ea4d7997a1291507295155",
            "value": " 0/1295 [00:00&lt;?, ?it/s]"
          }
        },
        "eed2a5881d5b4d7f889b206777a26cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced074a8ed73436abf6a7792b29c832a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f7ec9c5c29143ab844f40ad3ba3f5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "793f744d6d474792b9a96fc8d713d6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "782f15e7a03c40ae8bb439421861cba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a163dc44c805403ab13accfe7a840ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edcc758b05ea4d7997a1291507295155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardoskewes/68610finalprojectgroup48/blob/colab_branch/truly_final_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U8lv6t4dizPQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "rm -rf 68610finalprojectgroup48\n",
        "git clone https://github.com/ricardoskewes/68610finalprojectgroup48.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38VHNhKhgtjq",
        "outputId": "98a23298-d036-4c50-8e5a-eb4f8ce2780a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into '68610finalprojectgroup48'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu simpletransformers\n",
        "!pip install wordfreq\n",
        "!pip install wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sxSH2PXi75h",
        "outputId": "e9b47d26-f5e8-4645-a442-fe42e80cab65"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: simpletransformers in /usr/local/lib/python3.10/dist-packages (0.70.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (4.66.6)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (4.46.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (3.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.5.2)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.17.1)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.6.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.2.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.20.3)\n",
            "Requirement already satisfied: wandb>=0.10.32 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.18.7)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.41.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (0.4.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (2.19.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (2024.8.30)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->simpletransformers) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (3.11.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->simpletransformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->simpletransformers) (3.5.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (5.5.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (11.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (6.0.0)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (6.3.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (3.7)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (3.1.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.11)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\n",
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (6.3.1)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (3.5.0)\n",
            "Requirement already satisfied: locate<2.0.0,>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.1.0)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (2024.9.11)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1->wordfreq) (0.2.13)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes>=3.0->wordfreq) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes>=3.0->wordfreq) (1.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from marisa-trie>=1.1.0->language-data>=1.2->langcodes>=3.0->wordfreq) (75.1.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and imports"
      ],
      "metadata": {
        "id": "FY-dNU8wgxl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Append the cloned repository to sys.path\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/68610finalprojectgroup48\")\n",
        "projectDir = \"/content/68610finalprojectgroup48/tweepfake\"\n",
        "sys.path.insert(0, projectDir)\n",
        "resultsDir = projectDir+\"/data/results\"\n",
        "\n",
        "# Standard libraries\n",
        "import os\n",
        "import csv\n",
        "import logging\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "# Data manipulation libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLP libraries\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "from wordfreq import word_frequency\n",
        "\n",
        "#  confusion matrix stuff\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine learning libraries\n",
        "import torch\n",
        "from transformers import set_seed\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "\n",
        "# wandb library\n",
        "import wandb\n",
        "\n",
        "#DataHandler\n",
        "from DataHandler import DataHandler\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random_state = 523\n",
        "set_seed(random_state)\n"
      ],
      "metadata": {
        "id": "xtsJvTficTl4"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "swRXxgAuhgdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading code (unchanged)\n",
        "from DataHandler import DataHandler\n",
        "dh = DataHandler()\n",
        "\n",
        "# Paths to datasets\n",
        "csvTrainDataset = projectDir + \"/data/splits/train.csv\"\n",
        "csvValDataset = projectDir + \"/data/splits/validation.csv\"\n",
        "csvTestDataset = projectDir + \"/data/splits/test.csv\"\n",
        "\n",
        "# Load datasets\n",
        "dfTrain = dh.readCSVData(csvTrainDataset)\n",
        "dfVal = dh.readCSVData(csvValDataset)\n",
        "dfTest = dh.readCSVData(csvTestDataset)\n",
        "\n",
        "# Select interesting columns for this study\n",
        "dfTrainDataset = dfTrain[[\"screen_name\", \"text\", \"account.type\"]]\n",
        "dfValDataset = dfVal[[\"screen_name\", \"text\", \"account.type\"]]\n",
        "dfTestDataset = dfTest[[\"screen_name\", \"text\", \"account.type\"]]\n",
        "\n",
        "# Prepare training data\n",
        "X_train_all = dfTrainDataset.drop(columns=['screen_name'])\n",
        "X_train_all.columns = [\"text\", \"label\"]\n",
        "\n",
        "X_val_all = dfValDataset.drop(columns=['screen_name'])\n",
        "X_val_all.columns = [\"text\", \"label\"]\n",
        "\n",
        "X_test_all = dfTestDataset.drop(columns=['screen_name'])\n",
        "X_test_all.columns = [\"text\", \"label\"]\n",
        "\n",
        "# Map labels to integers\n",
        "dictLabels = {\"human\": 0, \"bot\": 1}\n",
        "\n",
        "X_train_all[\"label\"] = X_train_all[\"label\"].apply(lambda x: dictLabels[x])\n",
        "X_val_all[\"label\"] = X_val_all[\"label\"].apply(lambda x: dictLabels[x])\n",
        "X_test_all[\"label\"] = X_test_all[\"label\"].apply(lambda x: dictLabels[x])\n",
        "\n",
        "# Extract labels\n",
        "y_train = X_train_all[\"label\"]\n",
        "y_val = X_val_all[\"label\"]\n",
        "y_test = X_test_all[\"label\"]\n",
        "\n",
        "train_labels = y_train.tolist()\n",
        "val_labels = y_val.tolist()\n",
        "test_labels = y_test.tolist()\n"
      ],
      "metadata": {
        "id": "J_jOztOzcS3K"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Functions"
      ],
      "metadata": {
        "id": "SEQ7bb-jhzzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature creating functions (unchanged)\n",
        "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_spacy_doc(text):\n",
        "    return spacy_nlp(text)\n",
        "\n",
        "def switch_spacy_to_text(func):\n",
        "    def inner1(*args, **kwargs):\n",
        "        spacy_doc = get_spacy_doc(args[0])\n",
        "        return func(spacy_doc, **kwargs)\n",
        "    return inner1\n",
        "\n",
        "def count_words(text):\n",
        "    return len(text.split())  # C1\n",
        "\n",
        "def avg_word_length(text):\n",
        "    words = text.split()  # C2\n",
        "    return np.mean([len(w) for w in words])\n",
        "\n",
        "@switch_spacy_to_text\n",
        "def get_ANP(spacy_doc):\n",
        "    # Get total length (only tokens that are not punctuation or spaces)\n",
        "    filtered_tokens = [token for token in spacy_doc if not token.is_punct and not token.is_space]\n",
        "    total_tokens = len(filtered_tokens)\n",
        "\n",
        "    adjectives = [token.text for token in filtered_tokens if token.pos_ == \"ADJ\"]\n",
        "    nouns = [token.text for token in filtered_tokens if token.pos_ == \"NOUN\"]\n",
        "    pronouns = [token.text for token in filtered_tokens if token.pos_ == \"PRON\"]\n",
        "\n",
        "    if total_tokens == 0:\n",
        "        # If no valid tokens, set densities to 0 to avoid division by zero\n",
        "        adj_density = 0\n",
        "        noun_density = 0\n",
        "        pronoun_density = 0\n",
        "    else:\n",
        "        adj_density = len(adjectives) / total_tokens\n",
        "        noun_density = len(nouns) / total_tokens\n",
        "        pronoun_density = len(pronouns) / total_tokens\n",
        "\n",
        "    return adjectives, nouns, pronouns, adj_density, noun_density, pronoun_density\n",
        "\n",
        "def get_ANP_clean(text):\n",
        "    _, _, _, adj_density, noun_density, pronoun_density = get_ANP(text)\n",
        "    return adj_density, noun_density, pronoun_density  # C3\n",
        "\n",
        "@switch_spacy_to_text\n",
        "def get_capitalizations(spacy_doc):\n",
        "    capitalizations = [token.text for token in spacy_doc if token.text.isupper()]\n",
        "    return capitalizations, len(capitalizations) / len(spacy_doc)\n",
        "\n",
        "def get_capitalizations_clean(text):\n",
        "    _, cap_ratio = get_capitalizations(text)\n",
        "    return np.round(cap_ratio, 2)  # C4\n",
        "\n",
        "@switch_spacy_to_text\n",
        "def get_sentiment(spacy_doc):\n",
        "    polarity, subjectivity = TextBlob(spacy_doc.text).sentiment\n",
        "    return np.round(polarity, 3), np.round(subjectivity, 3)  # C5\n",
        "\n",
        "@switch_spacy_to_text\n",
        "def calculate_rarity_scores(spacy_doc, lang='en'):\n",
        "    adj_rarity_scores = []\n",
        "    noun_rarity_scores = []\n",
        "\n",
        "    for token in spacy_doc:\n",
        "        if token.pos_ == \"ADJ\":\n",
        "            adjective = token.text.lower()\n",
        "            freq = word_frequency(adjective, lang)\n",
        "            adj_rarity_score = -math.log(freq) if freq > 0 else 0\n",
        "            adj_rarity_scores.append(adj_rarity_score)\n",
        "        if token.pos_ == \"NOUN\":\n",
        "            noun = token.text.lower()\n",
        "            freq = word_frequency(noun, lang)\n",
        "            noun_rarity_score = -math.log(freq) if freq > 0 else 0\n",
        "            noun_rarity_scores.append(noun_rarity_score)\n",
        "    res = [0, 0]\n",
        "    # Calculate median rarity score over all NAs\n",
        "    if noun_rarity_scores:\n",
        "        res[0] = np.median(noun_rarity_scores)\n",
        "    if adj_rarity_scores:\n",
        "        res[1] = np.median(adj_rarity_scores)\n",
        "    return tuple(np.round(res, 3))\n",
        "\n",
        "@switch_spacy_to_text\n",
        "def get_punctuation(spacy_doc):\n",
        "    punctuation = [token.text for token in spacy_doc if token.pos_ == \"PUNCT\"]\n",
        "    return punctuation, len(punctuation) / len(spacy_doc)\n",
        "\n",
        "def get_punctuation_clean(text):\n",
        "    _, punct_ratio = get_punctuation(text)\n",
        "    return np.round(punct_ratio, 2)  # C7\n",
        "\n",
        "# Dictionary of classical features\n",
        "C = {\n",
        "    1: count_words,             # C1: Number of words in sentence\n",
        "    2: avg_word_length,         # C2: Average word length in sentence\n",
        "    3: get_ANP_clean,           # C3: Density scores of adjectives, pronouns, and nouns\n",
        "    4: get_capitalizations_clean,  # C4: Density of capital letters\n",
        "    5: get_sentiment,           # C5: Sentiment analysis\n",
        "    6: calculate_rarity_scores, # C6: Noun and adjective rarity scores\n",
        "    7: get_punctuation_clean    # C7: Density of punctuation\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VsA8zDPhk39",
        "outputId": "648fbf22-3de1-4228-892d-3bef29c291a1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model definitions"
      ],
      "metadata": {
        "id": "z6sszpdYjJxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model descriptions\n",
        "model_descriptions = {\n",
        "    1: 'BERT*(tweet)',\n",
        "    2: 'BERT*({tweet <SEP> C1 <SEP> C2 ...})',\n",
        "    3: 'BERT*({tweet <FEAT> C1 <FEAT> C2 ...})',\n",
        "}\n",
        "\n",
        "# Model-specific arguments (excluding hyperparameters). THESE ARE NOT MEANT TO BE SWEPT OVER, BUT JUST DEFINED.\n",
        "model_args_dict = {\n",
        "    1: {'transformer_type': 'bert', 'transformer_name': 'bert-base-cased', 'output_dir': 'type1'},\n",
        "    2: {'transformer_type': 'bert', 'transformer_name': 'bert-base-cased', 'output_dir': 'type2'},\n",
        "    3: {'separator_token_name': 'FEAT', 'transformer_type': 'bert', 'transformer_name': 'bert-base-cased', 'output_dir': 'type3'},  # Additional arguments can be added here\n",
        "    # Add arguments for models 4 to 9\n",
        "}\n",
        "\n",
        "# Define which hyperparameters are applicable to each model. THESE ARE MEANT TO BE ABLE TO BE SWEPT OVER. OVERRIDE DEFAULTS USING WANDB SWEEPS\n",
        "model_hyperparameters = {\n",
        "    1: {\"learning_rate\": 1e-5, \"train_batch_size\": 16, \"num_train_epochs\": 3,},\n",
        "    2: {\"learning_rate\": 1e-5, \"train_batch_size\": 16, \"num_train_epochs\": 3, \"C_ids\": [1,2]},\n",
        "    3: {\"learning_rate\": 1e-5, \"train_batch_size\": 16, \"num_train_epochs\": 3, \"C_ids\": [3,4,5]},\n",
        "}"
      ],
      "metadata": {
        "id": "cGVUaliQjIlK"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Initialize wandb\n"
      ],
      "metadata": {
        "id": "-lxrQxwyjhd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize wandb\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "# Set the wandb project name\n",
        "WANDB_PROJECT_NAME = \"6-861-finalproj\"\n"
      ],
      "metadata": {
        "id": "qxJvmgEZjbba"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ],
      "metadata": {
        "id": "YZxhABzPjdVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# all this thing outputs is the dictionary needed to append special tokens\n",
        "def create_special_tokens_dict(model_id, model_args_dict):\n",
        "    \"\"\"\n",
        "    Create a dictionary of special tokens based on the model_id.\n",
        "\n",
        "    Args:\n",
        "        model_id (int): The ID of the model to determine special tokens.\n",
        "        model_args_dict (dict): Dictionary of model-specific arguments.\n",
        "        hyperparameters (dict): Dictionary of hyperparameters for training.\n",
        "    Returns:\n",
        "        dict: Dictionary of special tokens.\n",
        "    \"\"\"\n",
        "    additional_tokens = []\n",
        "    if model_id == 3:\n",
        "        additional_tokens.append(model_args_dict['separator_token_name'])\n",
        "    return {'additional_special_tokens': additional_tokens}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def initialize_model_with_special_tokens (model_id, model_args_dict, hyperparameters, special_tokens_dict, model_descriptions):\n",
        "    \"\"\"\n",
        "    Initialize the model and tokenizer with special tokens.\n",
        "\n",
        "    Parameters:\n",
        "        transformer_type (str): The type of the transformer (e.g., 'bert').\n",
        "        transformer_name (str): The name of the pretrained transformer model.\n",
        "        model_id (int): The ID of the model.\n",
        "        hyperparameters (dict): Dictionary of hyperparameters, both for training (i.e., learning_rate,etc.) and otherwise fine-tunable (for some model_ids an example is numbeer of classical features).\n",
        "        model_args_dict: (dict): Dictionary of model-specific arguments.\n",
        "        special_tokens_dict (dict): Dictionary of special tokens to add.\n",
        "\n",
        "    Returns:\n",
        "        model: The initialized model.\n",
        "        tokenizer: The tokenizer with added special tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize model arguments\n",
        "    model_args = ClassificationArgs()\n",
        "    model_args.preprocessed = True\n",
        "    # model_args.dataset_format = \"arrow\"\n",
        "\n",
        "    # hyperparam\n",
        "    for param, value in hyperparameters[model_id].items():\n",
        "          setattr(model_args, param, value)\n",
        "\n",
        "    # Apply model-specific args.\n",
        "    for param, value in model_args_dict[model_id].items():\n",
        "        # Convert any parameter keys if needed\n",
        "        setattr(model_args, param, value)\n",
        "\n",
        "    # for param in model_args_dict[model_id]:\n",
        "    #     setattr(model_args, param, model_args_dict[model_id][param])\n",
        "\n",
        "\n",
        "    model_args.model_description = model_descriptions[model_id]\n",
        "\n",
        "    # Key settings for using HF datasets\n",
        "    model_args.reprocess_input_data = False\n",
        "    model_args.preprocessed = True\n",
        "    model_args.preprocess_inputs = False\n",
        "    model_args.sliding_window = False\n",
        "    model_args.use_hf_datasets = False\n",
        "    model_args.manual_seed = random_state\n",
        "    model_args.num_labels = 2\n",
        "    model_args.overwrite_output_dir = True\n",
        "    model_args.output_dir = f\"outputs/model_{model_id}\"\n",
        "\n",
        "\n",
        "\n",
        "    model = ClassificationModel(model_args_dict[model_id]['transformer_type'],\n",
        "                                model_args_dict[model_id]['transformer_name'],\n",
        "                                args=model_args,\n",
        "                                use_cuda=torch.cuda.is_available())\n",
        "    tokenizer = model.tokenizer\n",
        "    if model_args_dict[model_id]['transformer_type'] in ['bert', 'roberta']:\n",
        "      tokenizer.model_max_length = 512\n",
        "\n",
        "\n",
        "    # Add new special tokens\n",
        "    if special_tokens_dict:\n",
        "        tokenizer.add_special_tokens(special_tokens_dict)\n",
        "        model.model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "def encode_with_tokens(\n",
        "      tweet,\n",
        "      tokenizer,\n",
        "      feat_sep_token_id=None,\n",
        "      C_functions=None,\n",
        "      initial_token_id=None,\n",
        "      max_feature_tokens=None,\n",
        "      max_text_tokens=None\n",
        "  ):\n",
        "      \"\"\"\n",
        "      Encode a text and additional features with separation tokens, providing more flexible\n",
        "      control over how much space features and text occupy.\n",
        "\n",
        "      Parameters:\n",
        "          tweet (str): The main text to encode.\n",
        "          tokenizer: The Hugging Face tokenizer to use for encoding.\n",
        "          feat_sep_token_id (int): Token ID for the feature separator token. If None,\n",
        "              defaults to the model's sep or eos token.\n",
        "          C_functions (list): List of feature functions that take the tweet as input and\n",
        "              return a feature value (string, number, or tuple).\n",
        "          initial_token_id (int): The initial token ID (e.g., CLS or BOS). If None,\n",
        "              defaults to tokenizer.cls_token_id or tokenizer.bos_token_id.\n",
        "          max_feature_tokens (int): Maximum total number of tokens allocated to features.\n",
        "              If None, no specific limit other than model_max_length is enforced.\n",
        "          max_text_tokens (int): Maximum number of tokens allocated to the main text.\n",
        "              If None, no specific limit other than model_max_length is enforced.\n",
        "\n",
        "      Returns:\n",
        "          list: The final encoded sequence of token IDs.\n",
        "      \"\"\"\n",
        "      if initial_token_id is None:\n",
        "          initial_token_id = tokenizer.cls_token_id or tokenizer.bos_token_id\n",
        "\n",
        "      if feat_sep_token_id is None:\n",
        "          feat_sep_token_id = tokenizer.sep_token_id or tokenizer.eos_token_id\n",
        "\n",
        "      model_max_length = tokenizer.model_max_length\n",
        "\n",
        "      # Start sequence with initial token\n",
        "      encoded_sequence = [initial_token_id]\n",
        "\n",
        "      # Calculate a per-feature max length if applicable\n",
        "      feature_max_length = model_max_length  # default if no constraints\n",
        "      if C_functions and max_feature_tokens is not None and len(C_functions) > 0:\n",
        "          # Ensure a positive integer length\n",
        "          # For example, allocating 3x the max_feature_tokens across C_functions:\n",
        "          feature_max_length = int(max(1, (3 * max_feature_tokens) / len(C_functions)))\n",
        "      else:\n",
        "          # If no constraints, just rely on model_max_length\n",
        "          feature_max_length = model_max_length\n",
        "\n",
        "      # Encode features\n",
        "      feature_tokens = []\n",
        "      if C_functions is not None:\n",
        "          for func in C_functions:\n",
        "              feature_tokens.append(feat_sep_token_id)\n",
        "              feature_value = func(tweet)\n",
        "              if isinstance(feature_value, tuple):\n",
        "                  feature_value = ' '.join(map(str, feature_value))\n",
        "              else:\n",
        "                  feature_value = str(feature_value)\n",
        "\n",
        "              # Encode feature with truncation\n",
        "              encoded_feature = tokenizer.encode(\n",
        "                  feature_value,\n",
        "                  add_special_tokens=False,\n",
        "                  truncation=True,\n",
        "                  max_length=feature_max_length\n",
        "              )\n",
        "              feature_tokens.extend(encoded_feature)\n",
        "\n",
        "      # If there's a max_feature_tokens limit, truncate\n",
        "      if max_feature_tokens is not None and len(feature_tokens) > max_feature_tokens:\n",
        "          feature_tokens = feature_tokens[:max_feature_tokens]\n",
        "\n",
        "      # Add features to the main sequence\n",
        "      encoded_sequence.extend(feature_tokens)\n",
        "\n",
        "      # Compute available space for text\n",
        "      # Reserve one token for the final separator\n",
        "      available_for_text = model_max_length - len(encoded_sequence) - 1\n",
        "\n",
        "      # If max_text_tokens is provided, constrain further\n",
        "      if max_text_tokens is not None:\n",
        "          available_for_text = min(available_for_text, max_text_tokens)\n",
        "\n",
        "      # Ensure available_for_text is at least 1\n",
        "      available_for_text = max(1, available_for_text)\n",
        "\n",
        "      # Encode the main tweet text with truncation\n",
        "      # Add special tokens, but rely on manual truncation length computed above\n",
        "      encoded_tweet = tokenizer.encode(\n",
        "          tweet,\n",
        "          add_special_tokens=True,\n",
        "          truncation=True,\n",
        "          max_length=available_for_text\n",
        "      )\n",
        "\n",
        "      # If the initial token of encoded_tweet matches our initial_token_id, remove it\n",
        "      if encoded_tweet and encoded_tweet[0] == initial_token_id:\n",
        "          encoded_tweet = encoded_tweet[1:]\n",
        "\n",
        "      # Add truncated tweet tokens\n",
        "      encoded_sequence.extend(encoded_tweet)\n",
        "\n",
        "      # Add final separator token at the end\n",
        "      encoded_sequence.append(feat_sep_token_id)\n",
        "\n",
        "      # Final safety truncation if still somehow exceeded\n",
        "      if len(encoded_sequence) > model_max_length:\n",
        "          encoded_sequence = encoded_sequence[:model_max_length]\n",
        "\n",
        "      return encoded_sequence\n",
        "\n",
        "\n",
        "def encode_with_tokens_based_on_model_id(tweet, tokenizer, model_id, model_args_dict, model_hyperparameters):\n",
        "  if 'separator_token_name' in model_args_dict[model_id]:\n",
        "    feat_sep_token_id = tokenizer.convert_tokens_to_ids(model_args_dict['separator_token_name'])\n",
        "  else:\n",
        "    feat_sep_token_id = None\n",
        "\n",
        "  if 'C_ids' in model_hyperparameters[model_id]:\n",
        "    C_functions = [C[i] for i in model_hyperparameters[model_id]['C_ids']]\n",
        "  elif 'C_ids' in model_args_dict[model_id]:\n",
        "      C_functions = [C[i] for i in model_args_dict[model_id]['C_ids']]\n",
        "  else:\n",
        "      C_functions = None\n",
        "\n",
        "  max_feature_tokens = model_hyperparameters[model_id].get('max_feature_tokens', model_args_dict[model_id].get('max_feature_tokens', None))\n",
        "  # max_seq_length = model_hyperparameters[model_id].get('max_seq_length', model_args_dict[model_id].get('max_seq_length', None))\n",
        "\n",
        "  # if 'max_feature_tokens' in model_hyperparameters[model_id]:\n",
        "  #   max_feature_tokens = model_hyperparameters[model_id]['max_feature_tokens']\n",
        "  # elif 'max_feature_tokens' in model_args_dict[model_id]:\n",
        "  #   max_feature_tokens = model_args_dict[model_id]['max_feature_tokens']\n",
        "  # else:\n",
        "  #   max_feature_tokens = None\n",
        "\n",
        "  # if 'max_seq_length' in model_hyperparameters[model_id]:\n",
        "  #   max_seq_length = model_hyperparameters[model_id]['max_seq_length']\n",
        "  # elif 'max_seq_length' in model_args_dict[model_id]:\n",
        "  #   max_seq_length = model_args_dict[model_id]['max_seq_length']\n",
        "  # else:\n",
        "  #   max_seq_length = None\n",
        "\n",
        "  encoded_ids = encode_with_tokens(\n",
        "      tweet,\n",
        "      tokenizer,\n",
        "      feat_sep_token_id = feat_sep_token_id,\n",
        "      C_functions= C_functions,\n",
        "      initial_token_id = None,\n",
        "      max_feature_tokens=max_feature_tokens,\n",
        "      max_text_tokens = None\n",
        "      )\n",
        "\n",
        "  return encoded_ids\n",
        "\n",
        "def prepare_hf_dataset(X, model_id, model_args_dict, model_hyperparameters, tokenizer):\n",
        "    \"\"\"\n",
        "    Convert a dataframe with ['text', 'label'] into a dictionary suitable for\n",
        "    Simple Transformers\n",
        "\n",
        "    Simple Transformers will handle the data conversion internally. We just need\n",
        "    to provide a dictionary with 'input_ids', 'attention_mask', and 'labels'.\n",
        "    \"\"\"\n",
        "    max_length = tokenizer.model_max_length\n",
        "    input_ids_list = []\n",
        "    attention_masks = []\n",
        "    labels_list = []\n",
        "\n",
        "    for i, row in X.iterrows():\n",
        "        text = row['text']\n",
        "        label = row['label']\n",
        "        encoded_ids = encode_with_tokens_based_on_model_id(text, tokenizer, model_id, model_args_dict, model_hyperparameters)\n",
        "\n",
        "        # Pad/truncate\n",
        "        if len(encoded_ids) < max_length:\n",
        "            encoded_ids = encoded_ids + [tokenizer.pad_token_id] * (max_length - len(encoded_ids))\n",
        "        else:\n",
        "            encoded_ids = encoded_ids[:max_length]\n",
        "\n",
        "        # Create attention mask\n",
        "        attention_mask = [1 if token_id != tokenizer.pad_token_id else 0 for token_id in encoded_ids]\n",
        "\n",
        "        input_ids_list.append(encoded_ids)\n",
        "        attention_masks.append(attention_mask)\n",
        "        labels_list.append(label)\n",
        "\n",
        "    labels_list = [int(l) for l in labels_list]\n",
        "\n",
        "    data_dict = {\n",
        "        'input_ids': input_ids_list,\n",
        "        'attention_mask': attention_masks,\n",
        "        'labels': labels_list\n",
        "    }\n",
        "    df = pd.DataFrame(data_dict)\n",
        "    # assert all(isinstance(x, int) for x in df['labels']), \"All labels must be single integers, not lists.\"\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "m7OjgILC7cRD"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "v5wR2e8cjn26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model(X_train, X_val, model_id, model_hyperparameters, model_args_dict, wandb_project_name):\n",
        "    \"\"\"\n",
        "    Train a model based on the model_id and hyperparameters.\n",
        "\n",
        "    Args:\n",
        "        model_id (int): The ID of the model to train.\n",
        "        hyperparameters (dict): Dictionary of hyperparameters for training.\n",
        "\n",
        "    Returns:\n",
        "        model: The trained model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set up wandb run\n",
        "    current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    run_name = f\"Model_{model_id}_{current_time}\"\n",
        "    tags = [\n",
        "        f\"model_{model_id}\",\n",
        "        f\"date_{current_time.split('_')[0]}\",\n",
        "    ]\n",
        "    config_stuff = {**model_args_dict[model_id], **model_hyperparameters[model_id]}\n",
        "    # Add hyperparameters to tags\n",
        "    for param in config_stuff:\n",
        "        tags.append(f\"{param}_{config_stuff[param]}\")\n",
        "\n",
        "    # Initialize wandb run\n",
        "    run = wandb.init(\n",
        "        project=wandb_project_name,\n",
        "        name=run_name,\n",
        "        notes=model_descriptions[model_id],\n",
        "        tags=tags,\n",
        "        config=config_stuff\n",
        "    )\n",
        "\n",
        "    special_tokens_dict = create_special_tokens_dict(model_id, model_args_dict)\n",
        "    model, tokenizer = initialize_model_with_special_tokens(model_id, model_args_dict, model_hyperparameters, special_tokens_dict, model_descriptions)\n",
        "\n",
        "    train_dataset = prepare_hf_dataset(X_train, model_id, model_args_dict, model_hyperparameters, tokenizer)\n",
        "    val_dataset = prepare_hf_dataset(X_val, model_id, model_args_dict, model_hyperparameters, tokenizer)\n",
        "\n",
        "    # train_data_prepared = encode_with_tokens_based_on_model_id(X_train, tokenizer, model_id, model_args_dict, model_hyperparameters)\n",
        "    # val_data_prepared = encode_with_tokens_based_on_model_id(X_val, tokenizer, model_id, model_args_dict, model_hyperparameters)\n",
        "\n",
        "    # Log the model architecture\n",
        "    wandb.watch(model.model, log='all')\n",
        "\n",
        "    # Train the model\n",
        "    model.train_model(train_dataset, eval_data = val_dataset)\n",
        "\n",
        "    # Evaluate the model on validation data\n",
        "    result, model_outputs, wrong_predictions = model.eval_model(val_dataset)\n",
        "\n",
        "    # Log evaluation metrics\n",
        "    wandb.log(result)\n",
        "\n",
        "    # Log an example input (first input ids)\n",
        "    # wandb.log({'example_input_ids': train_dataset[0]['input_ids']})\n",
        "    wandb.log({'example_input_ids': train_dataset.iloc[0]['input_ids']})\n",
        "\n",
        "    # Log the model as an artifact with all necessary data for replication\n",
        "    artifact = wandb.Artifact(\n",
        "        name=f\"model_{model_id}_{run.id}\",\n",
        "        type='model',\n",
        "        description=model_descriptions[model_id],\n",
        "        metadata={\n",
        "            'model_id': model_id,\n",
        "            'model_hyperparams': model_hyperparameters[model_id],\n",
        "            'model_args': model_args_dict[model_id],\n",
        "            'random_state': random_state,\n",
        "        }\n",
        "    )\n",
        "    artifact.add_dir(model_args_dict.output_dir)\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    # # Finish wandb run\n",
        "    # run.finish()\n",
        "\n",
        "    return model, tokenizer\n"
      ],
      "metadata": {
        "id": "UW2t9oNwjnmW"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n"
      ],
      "metadata": {
        "id": "1z4csoL7jri1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(X_test, model_id, model, tokenizer, model_hyperparameters, model_args_dict, wandb_project_name):\n",
        "    \"\"\"\n",
        "    Evaluate the trained model on test data.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model.\n",
        "        X_test (DataFrame): Test data.\n",
        "        hyperparameters (dict): Hyperparameters used during training.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Prepare test data\n",
        "    # test_data_prepared = encode_with_tokens_based_on_model_id(X_test, tokenizer, model_id, model_args_dict, model_hyperparameters)\n",
        "    test_dataset = prepare_hf_dataset(X_test, model_id, model_args_dict, model_hyperparameters, tokenizer)\n",
        "\n",
        "    # Evaluate the model\n",
        "    # result, model_outputs, wrong_predictions = model.eval_model(test_data_prepared)\n",
        "    result, model_outputs, wrong_predictions = model.eval_model(test_dataset)\n",
        "\n",
        "    # Log evaluation metrics to wandb\n",
        "    wandb.log(result)\n",
        "\n",
        "    true_labels = np.array(test_dataset['labels'])\n",
        "\n",
        "    predictions = np.argmax(model_outputs, axis=1)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    # Log confusion matrix\n",
        "    wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "IvKz6fYrjqXG"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model, tokenizer = train_model(\n",
        "#         X_train_all,\n",
        "#         X_val_all,\n",
        "#         chosen_model_id,\n",
        "#         model_hyperparameters,\n",
        "#         model_args_dict,\n",
        "#         WANDB_PROJECT_NAME\n",
        "#     )"
      ],
      "metadata": {
        "id": "pkY5vh3ugIAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sweep config and training function"
      ],
      "metadata": {
        "id": "StNI2g5xtinG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sweep_train():\n",
        "    # Initialize the run for this set of hyperparameters\n",
        "    run = wandb.init()  # Do not remove this, this is the only init call\n",
        "\n",
        "    config = wandb.config\n",
        "    chosen_model_id = config.get('model_id', 1)\n",
        "\n",
        "    # Update hyperparameters based on config\n",
        "    if 'learning_rate' in config:\n",
        "        model_hyperparameters[chosen_model_id]['learning_rate'] = config.learning_rate\n",
        "    if 'train_batch_size' in config:\n",
        "        model_hyperparameters[chosen_model_id]['train_batch_size'] = config.train_batch_size\n",
        "    if 'num_train_epochs' in config:\n",
        "        model_hyperparameters[chosen_model_id]['num_train_epochs'] = config.num_train_epochs\n",
        "    if 'C_ids' in config:\n",
        "        model_hyperparameters[chosen_model_id]['C_ids'] = config.C_ids\n",
        "\n",
        "    # Train the model (do NOT call wandb.init inside train_model)\n",
        "    model, tokenizer = train_model(\n",
        "        X_train_all,\n",
        "        X_val_all,\n",
        "        chosen_model_id,\n",
        "        model_hyperparameters,\n",
        "        model_args_dict,\n",
        "        WANDB_PROJECT_NAME\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model(\n",
        "        X_test_all,\n",
        "        chosen_model_id,\n",
        "        model,\n",
        "        tokenizer,\n",
        "        model_hyperparameters,\n",
        "        model_args_dict,\n",
        "        WANDB_PROJECT_NAME\n",
        "    )\n",
        "\n",
        "    # Finish the run once everything is done\n",
        "    wandb.finish()\n",
        "\n"
      ],
      "metadata": {
        "id": "hOi4_U3etokY"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'metric': {'name': 'eval_loss', 'goal': 'minimize'},\n",
        "    'parameters': {\n",
        "        'model_id': {\n",
        "            'values': [2]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-5, 3e-5, 5e-5]\n",
        "        },\n",
        "        'train_batch_size': {\n",
        "            'values': [16, 32]\n",
        "        },\n",
        "        'C_ids': {\n",
        "            'values': [[1,2,3], [1,2,3,4,5,6,7]]\n",
        "        }\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "xG_No0wSthms"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT_NAME)\n",
        "wandb.agent(sweep_id, sweep_train, count= 1 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "700f6b03ec444318b224bdb68546c088",
            "302a2753dd404a09aa457f713e4d13fe",
            "2f6ce663aea14366a9a9813742e3cc5a",
            "08b72327eff44a4eaecb22890aee69f7",
            "13f84282ee3c413ca0ee439caa418751",
            "fd46c591fb0147d59a4ffdf0bb593254",
            "dbc5889c21684f7583a797e6d2819ec1",
            "f2a08f1022bd4a298903ffaf015bfe6a",
            "5c50d960352e41e8823d9d2d5605c570",
            "ffd2dc19e10f411fa6f593e09524cd0f",
            "6149b294eca940448285629e48f2f91b",
            "02d770f720884b7d9e23eac700919619",
            "883dd2ecee9946a7b1b06f422a1727cf",
            "a66afffe1faa41e5973daf8491d1a413",
            "ccea76e03c7d4ed69d7947d9e4560c28",
            "eed2a5881d5b4d7f889b206777a26cbd",
            "ced074a8ed73436abf6a7792b29c832a",
            "5f7ec9c5c29143ab844f40ad3ba3f5cf",
            "793f744d6d474792b9a96fc8d713d6c1",
            "782f15e7a03c40ae8bb439421861cba0",
            "a163dc44c805403ab13accfe7a840ba8",
            "edcc758b05ea4d7997a1291507295155"
          ]
        },
        "id": "h44KkxFGNRTb",
        "outputId": "44bdd7a8-9f3f-406c-d865-63a5d8a0e893"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: tv5336b2\n",
            "Sweep URL: https://wandb.ai/rskewes-harvard-university/6-861-finalproj/sweeps/tv5336b2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ql5y35xg with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tC_ids: [1, 2, 3]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_id: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241210_213530-ql5y35xg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg' target=\"_blank\">bright-sweep-1</a></strong> to <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/sweeps/tv5336b2' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj/sweeps/tv5336b2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/sweeps/tv5336b2' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj/sweeps/tv5336b2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:ql5y35xg) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">bright-sweep-1</strong> at: <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg</a><br/> View project at: <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241210_213530-ql5y35xg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:ql5y35xg). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241210_213532-ql5y35xg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg' target=\"_blank\">Model_2_2024-12-10_21-35-32</a></strong> to <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/sweeps/tv5336b2' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj/sweeps/tv5336b2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/sweeps/tv5336b2' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj/sweeps/tv5336b2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py:610: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_utils.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(cached_features_file)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "700f6b03ec444318b224bdb68546c088"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py:882: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running Epoch 1 of 3:   0%|          | 0/1295 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02d770f720884b7d9e23eac700919619"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py:905: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Model_2_2024-12-10_21-35-32</strong> at: <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj/runs/ql5y35xg</a><br/> View project at: <a href='https://wandb.ai/rskewes-harvard-university/6-861-finalproj' target=\"_blank\">https://wandb.ai/rskewes-harvard-university/6-861-finalproj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241210_213532-ql5y35xg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Run ql5y35xg errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-115-7f700197e6a1>\", line 19, in sweep_train\n",
            "    model, tokenizer = train_model(\n",
            "  File \"<ipython-input-113-5452b898e201>\", line 47, in train_model\n",
            "    model.train_model(train_dataset, eval_data = val_dataset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py\", line 630, in train_model\n",
            "    global_step, training_details = self.train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py\", line 906, in train\n",
            "    loss, *_ = self._calculate_loss(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py\", line 2340, in _calculate_loss\n",
            "    outputs = model(**inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1844, in _call_impl\n",
            "    return inner()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1790, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\", line 1703, in forward\n",
            "    loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\", line 1293, in forward\n",
            "    return F.cross_entropy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 3479, in cross_entropy\n",
            "    return torch._C._nn.cross_entropy_loss(\n",
            "ValueError: Expected input batch_size (16) to match target batch_size (8192).\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ql5y35xg errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-115-7f700197e6a1>\", line 19, in sweep_train\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model, tokenizer = train_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-113-5452b898e201>\", line 47, in train_model\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model.train_model(train_dataset, eval_data = val_dataset)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py\", line 630, in train_model\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     global_step, training_details = self.train(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py\", line 906, in train\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss, *_ = self._calculate_loss(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/simpletransformers/classification/classification_model.py\", line 2340, in _calculate_loss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = model(**inputs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1844, in _call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return inner()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1790, in inner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     result = forward_call(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\", line 1703, in forward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\", line 1293, in forward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.cross_entropy(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 3479, in cross_entropy\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return torch._C._nn.cross_entropy_loss(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Expected input batch_size (16) to match target batch_size (8192).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4odyLHrfemi3"
      },
      "execution_count": 104,
      "outputs": []
    }
  ]
}